{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31562f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Helper functions defined.\n",
      "Data generation functions for Challenge 1 defined.\n",
      "Directory './data/' ensured.\n",
      "Generating 5 warehouses...\n",
      "Generated warehouses_df with 5 rows.\n",
      "Generating 50 products...\n",
      "Generated products_df with 50 rows.\n",
      "Generating 150 inventory records...\n",
      "Generated inventory_df with 150 rows.\n",
      "Generating 150 demand forecast records...\n",
      "Generated demand_forecast_df with 150 rows.\n",
      "Generating transport costs matrix...\n",
      "Generated transport_costs_df with 20 rows.\n",
      "\n",
      "Saving datasets for Challenge 1...\n",
      "  Saved warehouses.csv (5 rows) to ./data/warehouses.csv\n",
      "  Saved products.csv (50 rows) to ./data/products.csv\n",
      "  Saved inventory.csv (150 rows) to ./data/inventory.csv\n",
      "  Saved demand_forecast.csv (150 rows) to ./data/demand_forecast.csv\n",
      "  Saved transport_costs.csv (20 rows) to ./data/transport_costs.csv\n",
      "  Saved README.md to ./data/README.md\n",
      "\n",
      "Challenge 1 data generation complete. Files saved in './data/'.\n",
      "\n",
      "Verifying generated files:\n",
      "\n",
      "--- demand_forecast.csv ---\n",
      "  warehouse_id product_id  forecasted_demand\n",
      "0        WH001     SKU004                105\n",
      "1        WH001     SKU030                262\n",
      "2        WH001     SKU032                177\n",
      "3        WH001     SKU006                 86\n",
      "4        WH003     SKU024                 55\n",
      "Shape: (150, 3)\n",
      "\n",
      "--- inventory.csv ---\n",
      "  warehouse_id product_id  current_stock\n",
      "0        WH003     SKU014            436\n",
      "1        WH001     SKU014            488\n",
      "2        WH003     SKU030            371\n",
      "3        WH002     SKU032            138\n",
      "4        WH001     SKU042            124\n",
      "Shape: (150, 3)\n",
      "\n",
      "--- products.csv ---\n",
      "  product_id    product_name        category   price\n",
      "0     SKU001       You Which            Toys   92.24\n",
      "1     SKU002      Tell Enter            Toys  189.06\n",
      "2     SKU003         Ok Such     Electronics  440.14\n",
      "3     SKU004      South Into  Sporting Goods  377.58\n",
      "4     SKU005  Meet Everybody         Apparel   77.55\n",
      "Shape: (50, 4)\n",
      "\n",
      "--- transport_costs.csv ---\n",
      "  from_warehouse_id to_warehouse_id  cost_per_unit\n",
      "0             WH001           WH002           2.25\n",
      "1             WH001           WH003           2.33\n",
      "2             WH001           WH004           0.83\n",
      "3             WH001           WH005           2.30\n",
      "4             WH002           WH001           2.01\n",
      "Shape: (20, 3)\n",
      "\n",
      "--- warehouses.csv ---\n",
      "  warehouse_id          location_name   latitude  longitude  capacity_sqm\n",
      "0        WH001         Mariaberg Area  24.938792  55.305516          5964\n",
      "1        WH002        Kellyshire Area  25.202075  55.484838          7668\n",
      "2        WH003    South Victoria Area  25.266972  55.072604          6328\n",
      "3        WH004       Shannonview Area  25.002593  55.235745          9134\n",
      "4        WH005  Lake Melissaside Area  25.184902  55.072369          1539\n",
      "Shape: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Wellington DAFZ Hackathon - DataGen - Challenge 1: Inventory\n",
    "\"\"\"\n",
    "\n",
    "# ## Wellington Campus x DAFZ AI Hackathon 2024: Data Generation\n",
    "#\n",
    "# ### Challenge 1: AI-Based Smart Redistribution Plan for Warehouse Inventory Balancing\n",
    "\n",
    "# ---\n",
    "# ### **Setup Guide for Participants**\n",
    "#\n",
    "# Follow these steps to set up your environment and run this notebook to generate the necessary mock data.\n",
    "#\n",
    "# **1. Create a Virtual Environment (Recommended):**\n",
    "#\n",
    "# A virtual environment keeps the Python packages for this project separate from others on your system. Open your terminal or command prompt:\n",
    "#\n",
    "# ```bash\n",
    "# # Navigate to the main 'Hackathon_Challenge_Notebooks' directory (or wherever you saved these files)\n",
    "# cd path/to/Hackathon_Challenge_Notebooks\n",
    "#\n",
    "# # Create a virtual environment named 'venv'\n",
    "# python -m venv venv\n",
    "# ```\n",
    "# *   If `python` doesn't work, try `python3`. You might need to install Python first if you don't have it.\n",
    "#\n",
    "# **2. Activate the Virtual Environment:**\n",
    "#\n",
    "# *   **Windows (Command Prompt):**\n",
    "#     ```bash\n",
    "#     venv\\Scripts\\activate\n",
    "#     ```\n",
    "# *   **Windows (Git Bash or PowerShell):**\n",
    "#     ```bash\n",
    "#     source venv/Scripts/activate\n",
    "#     ```\n",
    "# *   **macOS / Linux:**\n",
    "#     ```bash\n",
    "#     source venv/bin/activate\n",
    "#     ```\n",
    "# You should see `(venv)` appear at the beginning of your terminal prompt, indicating it's active.\n",
    "#\n",
    "# **3. Install Required Libraries:**\n",
    "#\n",
    "# While the environment is active, install the necessary Python packages:\n",
    "#\n",
    "# ```bash\n",
    "# pip install pandas numpy faker jupyterlab\n",
    "# ```\n",
    "# *   `pandas`: For data manipulation (DataFrames).\n",
    "# *   `numpy`: For numerical operations.\n",
    "# *   `faker`: To generate realistic mock data (names, addresses, etc.).\n",
    "# *   `jupyterlab`: To run this notebook interface.\n",
    "#\n",
    "# **4. Launch JupyterLab:**\n",
    "#\n",
    "# Start the JupyterLab server from your terminal (make sure `venv` is still active):\n",
    "#\n",
    "# ```bash\n",
    "# jupyter lab\n",
    "# ```\n",
    "# This should automatically open a new tab in your web browser. If not, copy the URL provided in the terminal (usually starting with `http://localhost:8888/lab`).\n",
    "#\n",
    "# **5. Open and Run This Notebook:**\n",
    "#\n",
    "# *   In the JupyterLab file browser (left panel), navigate into the `Challenge1_Inventory` folder.\n",
    "# *   Double-click on `Challenge1_Inventory_DataGen.ipynb` to open it.\n",
    "# *   To run the code:\n",
    "#     *   Select a code cell (it will have `In [ ]:` next to it).\n",
    "#     *   Press `Shift + Enter` to run the selected cell and move to the next one.\n",
    "#     *   Alternatively, use the \"Run\" menu at the top.\n",
    "# *   Run all the code cells in order from top to bottom.\n",
    "#\n",
    "# **6. Find Your Data:**\n",
    "#\n",
    "# After running all cells successfully, the generated CSV files will appear inside the `data` subfolder within this `Challenge1_Inventory` directory.\n",
    "#\n",
    "# **7. Deactivate the Virtual Environment (When Done):**\n",
    "#\n",
    "# Simply type `deactivate` in your terminal and press Enter.\n",
    "#\n",
    "# **Troubleshooting:**\n",
    "# *   `command not found (python/pip)`: Ensure Python is installed and added to your system's PATH, or use `python3`/`pip3`.\n",
    "# *   `ModuleNotFoundError`: Make sure you activated the virtual environment (`venv`) *before* running `pip install` and `jupyter lab`. Re-activate and try installing again.\n",
    "# *   Permission Errors: On macOS/Linux, you might need `sudo` for system-wide installs, but *avoid* using `sudo` with `pip` inside a virtual environment.\n",
    "# ---\n",
    "\n",
    "# ### Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# ### Configuration\n",
    "# You can adjust these numbers to generate smaller or larger datasets if needed.\n",
    "\n",
    "# Specific configuration for Challenge 1\n",
    "OUTPUT_DIR = './data/' # Save data in a subfolder relative to the notebook\n",
    "NUM_WAREHOUSES = 5\n",
    "NUM_PRODUCTS = 50\n",
    "NUM_INVENTORY_RECORDS = 150 # Should be <= NUM_WAREHOUSES * NUM_PRODUCTS\n",
    "NUM_FORECAST_RECORDS = 150 # Should be <= NUM_WAREHOUSES * NUM_PRODUCTS\n",
    "\n",
    "# Define product categories (needed for products.csv context)\n",
    "PRODUCT_CATEGORIES = ['Electronics', 'Apparel', 'Home Goods', 'Groceries', 'Books', 'Fashion Accessories', 'Sporting Goods', 'Toys']\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker('en')\n",
    "\n",
    "# ### Helper Functions\n",
    "# (Includes all potentially needed helpers)\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    \"\"\"Creates the directory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' ensured.\")\n",
    "\n",
    "def generate_ids(prefix, count):\n",
    "    \"\"\"Generates sequential IDs like WH001, WH002.\"\"\"\n",
    "    return [f\"{prefix}{i:03d}\" for i in range(1, count + 1)]\n",
    "\n",
    "def generate_order_ids(prefix, start_num, count):\n",
    "    \"\"\"Generates sequential order IDs like ORD1001, ORD1002.\"\"\"\n",
    "    return [f\"{prefix}{i}\" for i in range(start_num, start_num + count)]\n",
    "\n",
    "# Haversine distance function (needed for transport costs)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371 # Earth radius in kilometers\n",
    "    try:\n",
    "        # Add checks for valid numeric input\n",
    "        lat1, lon1, lat2, lon2 = map(float, [lat1, lon1, lat2, lon2])\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Warning: Invalid coordinates provided ({lat1}, {lon1}, {lat2}, {lon2}). Returning large distance.\")\n",
    "        return 99999 # Return a large distance or handle error appropriately\n",
    "\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dLat/2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "\n",
    "# ### Data Generation Functions for Challenge 1\n",
    "\n",
    "def generate_warehouses(num_warehouses):\n",
    "    print(f\"Generating {num_warehouses} warehouses...\")\n",
    "    warehouse_ids = generate_ids(\"WH\", num_warehouses)\n",
    "    data = {\n",
    "        'warehouse_id': warehouse_ids,\n",
    "        'location_name': [fake.city() + \" Area\" for _ in range(num_warehouses)],\n",
    "        'latitude': [random.uniform(24.9, 25.3) for _ in range(num_warehouses)],\n",
    "        'longitude': [random.uniform(55.0, 55.5) for _ in range(num_warehouses)],\n",
    "        'capacity_sqm': [random.randint(1000, 10000) for _ in range(num_warehouses)],\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated warehouses_df with {len(df)} rows.\")\n",
    "    return df, warehouse_ids\n",
    "\n",
    "def generate_products(num_products):\n",
    "    # Needed for inventory linking\n",
    "    print(f\"Generating {num_products} products...\")\n",
    "    product_ids = generate_ids(\"SKU\", num_products)\n",
    "    data = {\n",
    "        'product_id': product_ids,\n",
    "        # Use a combination of random words instead of the non-existent ecommerce_name\n",
    "'product_name': [f\"{fake.word().capitalize()} {fake.word().capitalize()}\" for _ in range(num_products)],\n",
    "        'category': [random.choice(PRODUCT_CATEGORIES) for _ in range(num_products)],\n",
    "        'price': np.round(np.random.uniform(5.0, 500.0, num_products), 2),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated products_df with {len(df)} rows.\")\n",
    "    return df, product_ids\n",
    "\n",
    "def generate_inventory(warehouse_ids, product_ids, num_inventory_records):\n",
    "    print(f\"Generating {num_inventory_records} inventory records...\")\n",
    "    max_possible = len(warehouse_ids) * len(product_ids)\n",
    "    if num_inventory_records > max_possible:\n",
    "        print(f\"Warning: num_inventory_records adjusted to max possible unique combinations ({max_possible})\")\n",
    "        num_inventory_records = max_possible\n",
    "\n",
    "    all_combinations = [(wh, prod) for wh in warehouse_ids for prod in product_ids]\n",
    "    if num_inventory_records > len(all_combinations):\n",
    "         num_inventory_records = len(all_combinations)\n",
    "    sampled_combinations = random.sample(all_combinations, num_inventory_records)\n",
    "\n",
    "    data = {\n",
    "        'warehouse_id': [combo[0] for combo in sampled_combinations],\n",
    "        'product_id': [combo[1] for combo in sampled_combinations],\n",
    "        'current_stock': [\n",
    "            random.choices(\n",
    "                [random.randint(500, 2000), random.randint(0, 50), random.randint(51, 499)],\n",
    "                weights=[0.1, 0.2, 0.7], k=1\n",
    "            )[0]\n",
    "            for _ in range(num_inventory_records)\n",
    "        ]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated inventory_df with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "def generate_demand_forecast(warehouse_ids, product_ids, num_forecast_records, inventory_df):\n",
    "    print(f\"Generating {num_forecast_records} demand forecast records...\")\n",
    "    if len(inventory_df) == 0:\n",
    "        print(\"Warning: Inventory DF is empty, cannot generate forecast based on it. Generating random combinations.\")\n",
    "        all_combinations = [(wh, prod) for wh in warehouse_ids for prod in product_ids]\n",
    "        if num_forecast_records > len(all_combinations):\n",
    "             num_forecast_records = len(all_combinations)\n",
    "        if not all_combinations:\n",
    "            print(\"Error: No warehouse or product IDs to generate forecasts.\")\n",
    "            return pd.DataFrame()\n",
    "        forecast_combinations_list = random.sample(all_combinations, num_forecast_records)\n",
    "        forecast_combinations = pd.DataFrame(forecast_combinations_list, columns=['warehouse_id', 'product_id'])\n",
    "    elif num_forecast_records > len(inventory_df):\n",
    "         print(f\"Warning: num_forecast_records adjusted to match inventory records ({len(inventory_df)})\")\n",
    "         num_forecast_records = len(inventory_df)\n",
    "         forecast_combinations = inventory_df[['warehouse_id', 'product_id']].copy()\n",
    "    else:\n",
    "        forecast_combinations = inventory_df[['warehouse_id', 'product_id']].sample(num_forecast_records, replace=False)\n",
    "\n",
    "    data = {\n",
    "        'warehouse_id': forecast_combinations['warehouse_id'].tolist(),\n",
    "        'product_id': forecast_combinations['product_id'].tolist(),\n",
    "        'forecasted_demand': [random.randint(10, 300) for _ in range(len(forecast_combinations))]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated demand_forecast_df with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "def generate_transport_costs(warehouses_df):\n",
    "    print(\"Generating transport costs matrix...\")\n",
    "    warehouse_ids = warehouses_df['warehouse_id'].tolist()\n",
    "    warehouse_coords = {row['warehouse_id']: (row['latitude'], row['longitude']) for index, row in warehouses_df.iterrows()}\n",
    "    data = {'from_warehouse_id': [], 'to_warehouse_id': [], 'cost_per_unit': []}\n",
    "\n",
    "    for wh_from in warehouse_ids:\n",
    "        for wh_to in warehouse_ids:\n",
    "            if wh_from == wh_to:\n",
    "                continue\n",
    "            lat1, lon1 = warehouse_coords[wh_from]\n",
    "            lat2, lon2 = warehouse_coords[wh_to]\n",
    "            distance = haversine(lat1, lon1, lat2, lon2)\n",
    "            base_cost = 0.5 + distance * 0.05 # Example: base AED + per km cost factor\n",
    "            cost = round(random.uniform(0.8, 1.2) * base_cost, 2)\n",
    "            data['from_warehouse_id'].append(wh_from)\n",
    "            data['to_warehouse_id'].append(wh_to)\n",
    "            data['cost_per_unit'].append(max(0.25, cost))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated transport_costs_df with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "print(\"Data generation functions for Challenge 1 defined.\")\n",
    "\n",
    "# ### Main Execution: Generate and Save Data\n",
    "\n",
    "ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "# Generate core data needed for this challenge\n",
    "warehouses_df, warehouse_ids = generate_warehouses(NUM_WAREHOUSES)\n",
    "products_df, product_ids = generate_products(NUM_PRODUCTS) # Include products for context\n",
    "\n",
    "# Generate challenge-specific data\n",
    "inventory_df = generate_inventory(warehouse_ids, product_ids, NUM_INVENTORY_RECORDS)\n",
    "demand_forecast_df = generate_demand_forecast(warehouse_ids, product_ids, NUM_FORECAST_RECORDS, inventory_df)\n",
    "transport_costs_df = generate_transport_costs(warehouses_df)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "datasets_to_save = {\n",
    "    \"warehouses.csv\": warehouses_df,\n",
    "    \"products.csv\": products_df, # Include products for context\n",
    "    \"inventory.csv\": inventory_df,\n",
    "    \"demand_forecast.csv\": demand_forecast_df,\n",
    "    \"transport_costs.csv\": transport_costs_df,\n",
    "}\n",
    "\n",
    "print(\"\\nSaving datasets for Challenge 1...\")\n",
    "for filename, df in datasets_to_save.items():\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    try:\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"  Saved {filename} ({len(df)} rows) to {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR saving {filename}: {e}\")\n",
    "\n",
    "# --- Create a simple README for the generated data ---\n",
    "readme_content = f\"\"\"# Challenge 1: Warehouse Inventory Balancing - Mock Data\n",
    "\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Files in this directory:\n",
    "*   **`warehouses.csv`**: Information about each warehouse (ID, location, coordinates).\n",
    "*   **`products.csv`**: Details about products (ID, name, category, price). Needed for context if joining inventory data.\n",
    "*   **`inventory.csv`**: Current stock levels for products in warehouses.\n",
    "*   **`demand_forecast.csv`**: Forecasted demand for products at specific warehouses.\n",
    "*   **`transport_costs.csv`**: Cost to transport items between warehouses.\n",
    "\"\"\"\n",
    "readme_path = os.path.join(OUTPUT_DIR, \"README.md\")\n",
    "try:\n",
    "    with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\"  Saved README.md to {readme_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"  ERROR saving README.md: {e}\")\n",
    "\n",
    "print(f\"\\nChallenge 1 data generation complete. Files saved in '{OUTPUT_DIR}'.\")\n",
    "\n",
    "\n",
    "# ### Verify Generated Data (Optional)\n",
    "# Load and display the first few rows of each generated CSV file.\n",
    "\n",
    "import glob\n",
    "\n",
    "print(\"\\nVerifying generated files:\")\n",
    "csv_files = glob.glob(os.path.join(OUTPUT_DIR, \"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the output directory.\")\n",
    "else:\n",
    "    for filepath in sorted(csv_files): # Sort for consistent order\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            print(f\"\\n--- {filename} ---\")\n",
    "            df_check = pd.read_csv(filepath)\n",
    "            print(df_check.head())\n",
    "            print(f\"Shape: {df_check.shape}\")\n",
    "            # Basic check for empty dataframe\n",
    "            if df_check.empty:\n",
    "                print(f\"Warning: {filename} is empty.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read or display {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce2046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
