{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31562f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Helper functions defined.\n",
      "Data generation functions for Challenge 1 defined.\n",
      "Directory './data/' ensured.\n",
      "Generating 5 warehouses...\n",
      "Generated warehouses_df with 5 rows.\n",
      "Generating 50 products...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Generator' object has no attribute 'ecommerce_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 268\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# Generate core data needed for this challenge\u001b[39;00m\n\u001b[32m    267\u001b[39m warehouses_df, warehouse_ids = generate_warehouses(NUM_WAREHOUSES)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m products_df, product_ids = \u001b[43mgenerate_products\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_PRODUCTS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Include products for context\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Generate challenge-specific data\u001b[39;00m\n\u001b[32m    271\u001b[39m inventory_df = generate_inventory(warehouse_ids, product_ids, NUM_INVENTORY_RECORDS)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 174\u001b[39m, in \u001b[36mgenerate_products\u001b[39m\u001b[34m(num_products)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_products\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m products...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    171\u001b[39m product_ids = generate_ids(\u001b[33m\"\u001b[39m\u001b[33mSKU\u001b[39m\u001b[33m\"\u001b[39m, num_products)\n\u001b[32m    172\u001b[39m data = {\n\u001b[32m    173\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mproduct_id\u001b[39m\u001b[33m'\u001b[39m: product_ids,\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m'\u001b[39m: \u001b[43m[\u001b[49m\u001b[43mfake\u001b[49m\u001b[43m.\u001b[49m\u001b[43mecommerce_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_products\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m    175\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m: [random.choice(PRODUCT_CATEGORIES) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_products)],\n\u001b[32m    176\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m: np.round(np.random.uniform(\u001b[32m5.0\u001b[39m, \u001b[32m500.0\u001b[39m, num_products), \u001b[32m2\u001b[39m),\n\u001b[32m    177\u001b[39m }\n\u001b[32m    178\u001b[39m df = pd.DataFrame(data)\n\u001b[32m    179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated products_df with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 174\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_products\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m products...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    171\u001b[39m product_ids = generate_ids(\u001b[33m\"\u001b[39m\u001b[33mSKU\u001b[39m\u001b[33m\"\u001b[39m, num_products)\n\u001b[32m    172\u001b[39m data = {\n\u001b[32m    173\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mproduct_id\u001b[39m\u001b[33m'\u001b[39m: product_ids,\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m'\u001b[39m: [\u001b[43mfake\u001b[49m\u001b[43m.\u001b[49m\u001b[43mecommerce_name\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_products)],\n\u001b[32m    175\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m: [random.choice(PRODUCT_CATEGORIES) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_products)],\n\u001b[32m    176\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m: np.round(np.random.uniform(\u001b[32m5.0\u001b[39m, \u001b[32m500.0\u001b[39m, num_products), \u001b[32m2\u001b[39m),\n\u001b[32m    177\u001b[39m }\n\u001b[32m    178\u001b[39m df = pd.DataFrame(data)\n\u001b[32m    179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated products_df with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Wellington Hackaton/myenv/lib/python3.11/site-packages/faker/proxy.py:130\u001b[39m, in \u001b[36mFaker.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mHandles cache access and proxying behavior\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m    126\u001b[39m \u001b[33;03m:param attr: attribute name\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03m:return: the appropriate attribute\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._factories) == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_factories\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generator_attrs:\n\u001b[32m    132\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mProxying calls to `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m` is not implemented in multiple locale mode.\u001b[39m\u001b[33m\"\u001b[39m % attr\n",
      "\u001b[31mAttributeError\u001b[39m: 'Generator' object has no attribute 'ecommerce_name'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Wellington DAFZ Hackathon - DataGen - Challenge 1: Inventory\n",
    "\"\"\"\n",
    "\n",
    "# ## Wellington Campus x DAFZ AI Hackathon 2024: Data Generation\n",
    "#\n",
    "# ### Challenge 1: AI-Based Smart Redistribution Plan for Warehouse Inventory Balancing\n",
    "\n",
    "# ---\n",
    "# ### **Setup Guide for Participants**\n",
    "#\n",
    "# Follow these steps to set up your environment and run this notebook to generate the necessary mock data.\n",
    "#\n",
    "# **1. Create a Virtual Environment (Recommended):**\n",
    "#\n",
    "# A virtual environment keeps the Python packages for this project separate from others on your system. Open your terminal or command prompt:\n",
    "#\n",
    "# ```bash\n",
    "# # Navigate to the main 'Hackathon_Challenge_Notebooks' directory (or wherever you saved these files)\n",
    "# cd path/to/Hackathon_Challenge_Notebooks\n",
    "#\n",
    "# # Create a virtual environment named 'venv'\n",
    "# python -m venv venv\n",
    "# ```\n",
    "# *   If `python` doesn't work, try `python3`. You might need to install Python first if you don't have it.\n",
    "#\n",
    "# **2. Activate the Virtual Environment:**\n",
    "#\n",
    "# *   **Windows (Command Prompt):**\n",
    "#     ```bash\n",
    "#     venv\\Scripts\\activate\n",
    "#     ```\n",
    "# *   **Windows (Git Bash or PowerShell):**\n",
    "#     ```bash\n",
    "#     source venv/Scripts/activate\n",
    "#     ```\n",
    "# *   **macOS / Linux:**\n",
    "#     ```bash\n",
    "#     source venv/bin/activate\n",
    "#     ```\n",
    "# You should see `(venv)` appear at the beginning of your terminal prompt, indicating it's active.\n",
    "#\n",
    "# **3. Install Required Libraries:**\n",
    "#\n",
    "# While the environment is active, install the necessary Python packages:\n",
    "#\n",
    "# ```bash\n",
    "# pip install pandas numpy faker jupyterlab\n",
    "# ```\n",
    "# *   `pandas`: For data manipulation (DataFrames).\n",
    "# *   `numpy`: For numerical operations.\n",
    "# *   `faker`: To generate realistic mock data (names, addresses, etc.).\n",
    "# *   `jupyterlab`: To run this notebook interface.\n",
    "#\n",
    "# **4. Launch JupyterLab:**\n",
    "#\n",
    "# Start the JupyterLab server from your terminal (make sure `venv` is still active):\n",
    "#\n",
    "# ```bash\n",
    "# jupyter lab\n",
    "# ```\n",
    "# This should automatically open a new tab in your web browser. If not, copy the URL provided in the terminal (usually starting with `http://localhost:8888/lab`).\n",
    "#\n",
    "# **5. Open and Run This Notebook:**\n",
    "#\n",
    "# *   In the JupyterLab file browser (left panel), navigate into the `Challenge1_Inventory` folder.\n",
    "# *   Double-click on `Challenge1_Inventory_DataGen.ipynb` to open it.\n",
    "# *   To run the code:\n",
    "#     *   Select a code cell (it will have `In [ ]:` next to it).\n",
    "#     *   Press `Shift + Enter` to run the selected cell and move to the next one.\n",
    "#     *   Alternatively, use the \"Run\" menu at the top.\n",
    "# *   Run all the code cells in order from top to bottom.\n",
    "#\n",
    "# **6. Find Your Data:**\n",
    "#\n",
    "# After running all cells successfully, the generated CSV files will appear inside the `data` subfolder within this `Challenge1_Inventory` directory.\n",
    "#\n",
    "# **7. Deactivate the Virtual Environment (When Done):**\n",
    "#\n",
    "# Simply type `deactivate` in your terminal and press Enter.\n",
    "#\n",
    "# **Troubleshooting:**\n",
    "# *   `command not found (python/pip)`: Ensure Python is installed and added to your system's PATH, or use `python3`/`pip3`.\n",
    "# *   `ModuleNotFoundError`: Make sure you activated the virtual environment (`venv`) *before* running `pip install` and `jupyter lab`. Re-activate and try installing again.\n",
    "# *   Permission Errors: On macOS/Linux, you might need `sudo` for system-wide installs, but *avoid* using `sudo` with `pip` inside a virtual environment.\n",
    "# ---\n",
    "\n",
    "# ### Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# ### Configuration\n",
    "# You can adjust these numbers to generate smaller or larger datasets if needed.\n",
    "\n",
    "# Specific configuration for Challenge 1\n",
    "OUTPUT_DIR = './data/' # Save data in a subfolder relative to the notebook\n",
    "NUM_WAREHOUSES = 5\n",
    "NUM_PRODUCTS = 50\n",
    "NUM_INVENTORY_RECORDS = 150 # Should be <= NUM_WAREHOUSES * NUM_PRODUCTS\n",
    "NUM_FORECAST_RECORDS = 150 # Should be <= NUM_WAREHOUSES * NUM_PRODUCTS\n",
    "\n",
    "# Define product categories (needed for products.csv context)\n",
    "PRODUCT_CATEGORIES = ['Electronics', 'Apparel', 'Home Goods', 'Groceries', 'Books', 'Fashion Accessories', 'Sporting Goods', 'Toys']\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker('en')\n",
    "\n",
    "# ### Helper Functions\n",
    "# (Includes all potentially needed helpers)\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    \"\"\"Creates the directory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' ensured.\")\n",
    "\n",
    "def generate_ids(prefix, count):\n",
    "    \"\"\"Generates sequential IDs like WH001, WH002.\"\"\"\n",
    "    return [f\"{prefix}{i:03d}\" for i in range(1, count + 1)]\n",
    "\n",
    "def generate_order_ids(prefix, start_num, count):\n",
    "    \"\"\"Generates sequential order IDs like ORD1001, ORD1002.\"\"\"\n",
    "    return [f\"{prefix}{i}\" for i in range(start_num, start_num + count)]\n",
    "\n",
    "# Haversine distance function (needed for transport costs)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371 # Earth radius in kilometers\n",
    "    try:\n",
    "        # Add checks for valid numeric input\n",
    "        lat1, lon1, lat2, lon2 = map(float, [lat1, lon1, lat2, lon2])\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Warning: Invalid coordinates provided ({lat1}, {lon1}, {lat2}, {lon2}). Returning large distance.\")\n",
    "        return 99999 # Return a large distance or handle error appropriately\n",
    "\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dLat/2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "\n",
    "# ### Data Generation Functions for Challenge 1\n",
    "\n",
    "def generate_warehouses(num_warehouses):\n",
    "    print(f\"Generating {num_warehouses} warehouses...\")\n",
    "    warehouse_ids = generate_ids(\"WH\", num_warehouses)\n",
    "    data = {\n",
    "        'warehouse_id': warehouse_ids,\n",
    "        'location_name': [fake.city() + \" Area\" for _ in range(num_warehouses)],\n",
    "        'latitude': [random.uniform(24.9, 25.3) for _ in range(num_warehouses)],\n",
    "        'longitude': [random.uniform(55.0, 55.5) for _ in range(num_warehouses)],\n",
    "        'capacity_sqm': [random.randint(1000, 10000) for _ in range(num_warehouses)],\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated warehouses_df with {len(df)} rows.\")\n",
    "    return df, warehouse_ids\n",
    "\n",
    "def generate_products(num_products):\n",
    "    # Needed for inventory linking\n",
    "    print(f\"Generating {num_products} products...\")\n",
    "    product_ids = generate_ids(\"SKU\", num_products)\n",
    "    data = {\n",
    "        'product_id': product_ids,\n",
    "        # Use a combination of random words instead of the non-existent ecommerce_name\n",
    "'product_name': [f\"{fake.word().capitalize()} {fake.word().capitalize()}\" for _ in range(num_products)],\n",
    "        'category': [random.choice(PRODUCT_CATEGORIES) for _ in range(num_products)],\n",
    "        'price': np.round(np.random.uniform(5.0, 500.0, num_products), 2),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated products_df with {len(df)} rows.\")\n",
    "    return df, product_ids\n",
    "\n",
    "def generate_inventory(warehouse_ids, product_ids, num_inventory_records):\n",
    "    print(f\"Generating {num_inventory_records} inventory records...\")\n",
    "    max_possible = len(warehouse_ids) * len(product_ids)\n",
    "    if num_inventory_records > max_possible:\n",
    "        print(f\"Warning: num_inventory_records adjusted to max possible unique combinations ({max_possible})\")\n",
    "        num_inventory_records = max_possible\n",
    "\n",
    "    all_combinations = [(wh, prod) for wh in warehouse_ids for prod in product_ids]\n",
    "    if num_inventory_records > len(all_combinations):\n",
    "         num_inventory_records = len(all_combinations)\n",
    "    sampled_combinations = random.sample(all_combinations, num_inventory_records)\n",
    "\n",
    "    data = {\n",
    "        'warehouse_id': [combo[0] for combo in sampled_combinations],\n",
    "        'product_id': [combo[1] for combo in sampled_combinations],\n",
    "        'current_stock': [\n",
    "            random.choices(\n",
    "                [random.randint(500, 2000), random.randint(0, 50), random.randint(51, 499)],\n",
    "                weights=[0.1, 0.2, 0.7], k=1\n",
    "            )[0]\n",
    "            for _ in range(num_inventory_records)\n",
    "        ]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated inventory_df with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "def generate_demand_forecast(warehouse_ids, product_ids, num_forecast_records, inventory_df):\n",
    "    print(f\"Generating {num_forecast_records} demand forecast records...\")\n",
    "    if len(inventory_df) == 0:\n",
    "        print(\"Warning: Inventory DF is empty, cannot generate forecast based on it. Generating random combinations.\")\n",
    "        all_combinations = [(wh, prod) for wh in warehouse_ids for prod in product_ids]\n",
    "        if num_forecast_records > len(all_combinations):\n",
    "             num_forecast_records = len(all_combinations)\n",
    "        if not all_combinations:\n",
    "            print(\"Error: No warehouse or product IDs to generate forecasts.\")\n",
    "            return pd.DataFrame()\n",
    "        forecast_combinations_list = random.sample(all_combinations, num_forecast_records)\n",
    "        forecast_combinations = pd.DataFrame(forecast_combinations_list, columns=['warehouse_id', 'product_id'])\n",
    "    elif num_forecast_records > len(inventory_df):\n",
    "         print(f\"Warning: num_forecast_records adjusted to match inventory records ({len(inventory_df)})\")\n",
    "         num_forecast_records = len(inventory_df)\n",
    "         forecast_combinations = inventory_df[['warehouse_id', 'product_id']].copy()\n",
    "    else:\n",
    "        forecast_combinations = inventory_df[['warehouse_id', 'product_id']].sample(num_forecast_records, replace=False)\n",
    "\n",
    "    data = {\n",
    "        'warehouse_id': forecast_combinations['warehouse_id'].tolist(),\n",
    "        'product_id': forecast_combinations['product_id'].tolist(),\n",
    "        'forecasted_demand': [random.randint(10, 300) for _ in range(len(forecast_combinations))]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated demand_forecast_df with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "def generate_transport_costs(warehouses_df):\n",
    "    print(\"Generating transport costs matrix...\")\n",
    "    warehouse_ids = warehouses_df['warehouse_id'].tolist()\n",
    "    warehouse_coords = {row['warehouse_id']: (row['latitude'], row['longitude']) for index, row in warehouses_df.iterrows()}\n",
    "    data = {'from_warehouse_id': [], 'to_warehouse_id': [], 'cost_per_unit': []}\n",
    "\n",
    "    for wh_from in warehouse_ids:\n",
    "        for wh_to in warehouse_ids:\n",
    "            if wh_from == wh_to:\n",
    "                continue\n",
    "            lat1, lon1 = warehouse_coords[wh_from]\n",
    "            lat2, lon2 = warehouse_coords[wh_to]\n",
    "            distance = haversine(lat1, lon1, lat2, lon2)\n",
    "            base_cost = 0.5 + distance * 0.05 # Example: base AED + per km cost factor\n",
    "            cost = round(random.uniform(0.8, 1.2) * base_cost, 2)\n",
    "            data['from_warehouse_id'].append(wh_from)\n",
    "            data['to_warehouse_id'].append(wh_to)\n",
    "            data['cost_per_unit'].append(max(0.25, cost))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated transport_costs_df with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "print(\"Data generation functions for Challenge 1 defined.\")\n",
    "\n",
    "# ### Main Execution: Generate and Save Data\n",
    "\n",
    "ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "# Generate core data needed for this challenge\n",
    "warehouses_df, warehouse_ids = generate_warehouses(NUM_WAREHOUSES)\n",
    "products_df, product_ids = generate_products(NUM_PRODUCTS) # Include products for context\n",
    "\n",
    "# Generate challenge-specific data\n",
    "inventory_df = generate_inventory(warehouse_ids, product_ids, NUM_INVENTORY_RECORDS)\n",
    "demand_forecast_df = generate_demand_forecast(warehouse_ids, product_ids, NUM_FORECAST_RECORDS, inventory_df)\n",
    "transport_costs_df = generate_transport_costs(warehouses_df)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "datasets_to_save = {\n",
    "    \"warehouses.csv\": warehouses_df,\n",
    "    \"products.csv\": products_df, # Include products for context\n",
    "    \"inventory.csv\": inventory_df,\n",
    "    \"demand_forecast.csv\": demand_forecast_df,\n",
    "    \"transport_costs.csv\": transport_costs_df,\n",
    "}\n",
    "\n",
    "print(\"\\nSaving datasets for Challenge 1...\")\n",
    "for filename, df in datasets_to_save.items():\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    try:\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"  Saved {filename} ({len(df)} rows) to {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR saving {filename}: {e}\")\n",
    "\n",
    "# --- Create a simple README for the generated data ---\n",
    "readme_content = f\"\"\"# Challenge 1: Warehouse Inventory Balancing - Mock Data\n",
    "\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Files in this directory:\n",
    "*   **`warehouses.csv`**: Information about each warehouse (ID, location, coordinates).\n",
    "*   **`products.csv`**: Details about products (ID, name, category, price). Needed for context if joining inventory data.\n",
    "*   **`inventory.csv`**: Current stock levels for products in warehouses.\n",
    "*   **`demand_forecast.csv`**: Forecasted demand for products at specific warehouses.\n",
    "*   **`transport_costs.csv`**: Cost to transport items between warehouses.\n",
    "\"\"\"\n",
    "readme_path = os.path.join(OUTPUT_DIR, \"README.md\")\n",
    "try:\n",
    "    with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\"  Saved README.md to {readme_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"  ERROR saving README.md: {e}\")\n",
    "\n",
    "print(f\"\\nChallenge 1 data generation complete. Files saved in '{OUTPUT_DIR}'.\")\n",
    "\n",
    "\n",
    "# ### Verify Generated Data (Optional)\n",
    "# Load and display the first few rows of each generated CSV file.\n",
    "\n",
    "import glob\n",
    "\n",
    "print(\"\\nVerifying generated files:\")\n",
    "csv_files = glob.glob(os.path.join(OUTPUT_DIR, \"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the output directory.\")\n",
    "else:\n",
    "    for filepath in sorted(csv_files): # Sort for consistent order\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            print(f\"\\n--- {filename} ---\")\n",
    "            df_check = pd.read_csv(filepath)\n",
    "            print(df_check.head())\n",
    "            print(f\"Shape: {df_check.shape}\")\n",
    "            # Basic check for empty dataframe\n",
    "            if df_check.empty:\n",
    "                print(f\"Warning: {filename} is empty.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read or display {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce2046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
